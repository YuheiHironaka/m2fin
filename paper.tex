\documentclass[12pt,epsf,dvipdfmx]{jreport}
% \usepackage{graphicx} % 図の貼り付け用 (ics.styで読み込まれているためコメントアウト)
\usepackage{ics} % ICS卒論・修論スタイルファイル
\usepackage{makeidx} %索引生成用パッケージ
\usepackage{tabularx}% 横幅指定で表を作成
\usepackage{latexsym} % 数学記号用パッケージ

\usepackage{hhline}
\usepackage{here}

\usepackage{url}
\urlstyle{same}


\newtheorem{definition}{定義}[chapter]
\newtheorem{algorithm}{アルゴリズム}[chapter]

%% end of local definitions

\def\epsfsize#1#2{\ifnum#1>\hsize\hsize\else#1\fi}

\begin{document}

% \papercode{ICS-xxM-yyyyyyy} % 論文番号については，「論文番号および論文ファイル名について」のwebページを確認してください．
% \title{卒業論文，修士論文のタイトル}
% % \affiliation{工学部情報工学科}
% \affiliation{理工学研究科 数理電子情報専攻\\情報工学プログラム}
% % \affiliation{理工学研究科 数理電子情報コース}
% \author{氏 名}
% \date{令和7年2月10日提出}
% \supervisor{○○ ☆☆教授}
% \labname{○○研究室}
% \studentID{yyyyyyy}
% \maketitle

\papercode{ICS-26M-24MM322}
\title{2D-LiDARを用いた足元計測に基づく人物行動の理解}
\affiliation{理工学研究科 数理電子情報専攻\\情報工学プログラム}
\author{廣中 優平}
\date{令和8年2月5日提出}
\supervisor{小林 貴訓教授}
\labname{小林研究室}
\studentID{24MM322}
\maketitle

\setcounter{page}{1}
\chapter*{概要}
 \pagenumbering{roman} % 消さない
 \addcontentsline{toc}{chapter}{概要} %消さない


人物の動きを計測・理解することは，様々な場面で非常に重要である．近年では人と共存するロボットも数多く登場し，人の位置を正しく検出・追跡したり，個人の振る舞いを理解したりすることの重要性は一層増している．現在行われている人物計測の多くはカメラ画像を用いており，詳細な計測を行うことができるものの，公共空間における計測ではプライバシーの問題が懸念される．

先行研究では，足元の高さに設置した2D-LiDARを用いて人物の動きを計測することで，プライバシーの問題の解決を目指してきた．具体的には，2D-LiDARによる足元計測データの複数フレームを重ねて人物の動きを表現した時系列画像に対して，クラスタリング手法による人物の検出とカルマンフィルタによる追跡を行うことで，精度の高い歩行者追跡を実現している．また，2D-LiDAR計測データから歩行者の全身骨格を推定する研究も行われてきた．先述の2D-LiDARによる時系列画像に，Kinectから取得した骨格情報を組み合わせて深層学習を行うことで，足元計測のみで歩行者の3次元全身骨格をおおよそ推定できる枠組みを実現している．これらの技術はどれも非常に有用なものであるが，複数人が歩行して遮蔽が多発する場合に追跡性能が落ちる点，クラスタリングの処理速度が遅くリアルタイムでの追跡に向かない点，それぞれが個別に実装されている点など，実用に向けていくつかの問題点があった．本研究ではそれらを解消した統合的なシステムの実装をめざす．

歩行者追跡における課題については，カメラ画像に用いられてきた複数物体追跡技術を，2D-LiDARによる足元計測データに応用することで解消する．2D-LiDARより得られるデータはカメラ画像に比べて情報量が少ないため，対象の見た目の特徴を追跡の手がかりとしない手法であるByteTrackのアルゴリズムを適用する．時系列画像中の人物を検出できるように学習を行ったYOLOXと，遮蔽に強いBYTEアルゴリズムを組み合わせることで，従来の手法よりも持続性の高い追跡をリアルタイムで実行できるようになった．実際に複数人の歩行に対して，ByteTrackベースの提案手法と従来の手法のそれぞれを用いて追跡を行い，定量的な性能の比較を行ったところ，良好な結果を得た．骨格推定との統合については，検出・追跡に用いた時系列画像の中で追跡領域を切り取った画像に対して骨格推定モデルを適用することで，検出・追跡と同時にリアルタイムで全身骨格を推定する．また，追跡と全身骨格推定の結果を組み合わせて3次元空間に描画することで，空間内にいる歩行者の動きを直感的に理解できるシステムを実現した．実際に複数の歩行者がいる環境において，本システムの実用性を確認した．



%%% 謝辞 %%%

\chapter*{謝辞}
\addcontentsline{toc}{chapter}{謝辞} % 消さない

%卒論の謝辞
研究ならびに生活面においてご指導を賜りました小林教授，鈴木助教に深く感謝致します．

また，研究室の皆様，そして同期学生の皆様，並びに私を暖かく見守って頂いた両親はじめとする周囲のすべての皆様に深く感謝致します．

\tableofcontents % 目次生成
\listoffigures % 図目次生成
\addcontentsline{toc}{chapter}{図目次}
\listoftables % 表目次生成
\addcontentsline{toc}{chapter}{表目次}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{はじめに}
\pagenumbering{arabic} %消さないこと
\setcounter{page}{1}   %消さないこと

       \section{背景}
       人物の動きを正しく計測することは，様々な場面で非常に重要になっている．複数人物の位置を正しく検出・追跡したり，それぞれの振る舞いを理解することは，公共空間における空間利用の最適化や，利用者の利便性向上に向けた環境設計において重要な役割を果たす．
       また，近年では人と共存するロボットも多く登場し，それらの振る舞いを最適化する際にも人物の行動を正しく理解することが求められる．

       複数人物の行動理解には，カメラ画像が用いられることが多い．カメラ画像は情報量が多いため，簡単に行動の解析ができる．一方で，公共空間での撮影ではプライバシーの問題が発生する．不特定多数が利用する公共空間において，カメラ画像による計測を行うと，顔などの重要度の高い個人情報を収集することなる．カメラ画像を用いて歩行者計測を行う場合は，個人が特定されない形での情報処理や利用用途の正しい告知などが求められ，計測を行うハードルが高い．


       \section{目的}
       本研究では，人流計測やロボットの振る舞い向上に向けた人物の行動計測手法として，足元の高さに設置した2D-LiDARで取得できるデータを使って，歩行者の行動を理解するシステムの実現を目指す．2D-LiDARで取得するのは足元の距離データのみであり，カメラ画像と比べると情報量が極めて少ない．プライバシーに関して考慮すべき事項が減ることで，様々な場面で歩行者計測が容易に行えるようになると考える．
       
       本研究の取り組みは，歩行者検出・追跡の性能改善，骨格推定と統合したシステムの実装の2つに分けられる．これまでに小林研究室で行われてきた歩行者検出・追跡の課題を解消し，高速かつ高精度の検出・追跡を実現した．さらに，これまで検出・追跡とは分かれて研究されてきた3次元骨格推定システムを統合することで，検出・追跡と骨格推定を同時にリアルタイムで行える実用性の高いシステムを実現した．
       


       \section{本論文の構成}
       本論文の構成は以下のようになっている．

              第1章 はじめに

              第2章 先行研究

              第3章 システムの概要

              第4章 実験と考察

              第5章 おわりに

       第1章では，本研究の背景と目的，そして本論文の構成を説明する．第2章では，これまでに行われてきた人物計測手法について述べる．第3章では，本研究にて目指すシステムの構成を説明する．第4章では，実装したシステムの性能を評価するための実験とその結果，考察について述べる．第5章では，本稿のまとめと今後の課題について述べる．


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{先行研究}
本研究で実装する歩行者計測システムに関わる先行研究を紹介する．
       \section{従来の歩行者追跡}
       小林研究室では，以前より足元の高さに設置した2D-LiDARを用いた歩行者追跡が行われている\cite{hasan2021person}\cite{h_b}\cite{h_m}．先行研究では，クラスタリングを用いた検出とカルマンフィルタを用いた追跡によって，歩行者追跡を実現していた．本節では先行研究の概要について説明する．
              \subsection{クラスタリングによる検出}
              先行研究\cite{hasan2021person}\cite{h_b}\cite{h_m}では，クラスタリングを用いて人物の検出を行っていた．クラスタリングアルゴリズムは，DBSCAN\cite{db}をベースとしている．DBSCANはデータの密度を基にクラスタリングを行うアルゴリズムである．
 
              2D-LiDARによって取得された人物の足は，図\ref{fig:dis}のように描画される．本稿ではこれを距離画像と呼ぶ．距離画像に対してクラスタリングを行うと，正しく人を検出することができない場合がある．右足と左足が離れている場合に2人であると検出してしまう問題や，複数人が近接する場合に1人であると検出してしまう問題が発生する．そこで先行研究では，過去フレームの画像を重ね合わせた画像(図\ref{fig:mhi})をクラスタリングに用いている．本稿ではこれを時系列画像と呼ぶ．時系列画像は現在の足の位置だけでなく過去の動きを表現できるため，前述の問題を解消できる．

              \begin{figure}[H]
              \centering
              \begin{minipage}{0.4\columnwidth}
                     \centering
                     \includegraphics[width=\columnwidth]{dis.png}
                     \caption[距離画像]{距離画像(\cite{h_m}図3.4より)}
                     \label{fig:dis}
              \end{minipage}
              \hspace{0.04\columnwidth} %
              \begin{minipage}{0.4\columnwidth}
                     \centering
                     \includegraphics[width=\columnwidth]{mhi.png}
                     \caption[時系列画像]{時系列画像(\cite{h_m}図3.4より)}
                     \label{fig:mhi}
              \end{minipage}
              \end{figure}


              \subsection{カルマンフィルタによる追跡}
              クラスタリングによって検出された人物に対して，重心位置を計算してカルマンフィルタを適用する(図\ref{fig:gra}，図\ref{fig:kal})．カルマンフィルタでは，1ステップ前の状態から推定した位置と検出した位置より，現在の推定位置の決定と1ステップ先の推定が行われる．これによって，時間とともに動いていく人物を追跡する．

              以上のような手法によって，2D-LiDARの周辺の歩行者の追跡を行っていた．多くの場合において，複数の人物を正しく追跡することができていた．

              \begin{figure}[H]
              \centering
              \begin{minipage}{0.4\columnwidth}
                     \centering
                     \includegraphics[width=\columnwidth]{gra.png}
                     \caption[重心位置を計算]{重心位置を計算\newline 
                     (\cite{h_m}図3.7より)}
                     \label{fig:gra}
              \end{minipage}
              \hspace{0.04\columnwidth} 
              \begin{minipage}{0.4\columnwidth}
                     \centering
                     \includegraphics[width=\columnwidth]{kal.png}
                     \caption[カルマンフィルタを適用]{カルマンフィルタを適用\newline 
                     (\cite{h_m}図3.8より)}
                     \label{fig:kal}
              \end{minipage}
              \end{figure}

              \subsection{従来手法の課題}
              一方で，先行研究\cite{hasan2021person}\cite{h_b}\cite{h_m}にはいくつかの問題点も存在した．まず，追跡対象が他の人物の影に入って計測されなくなる場合に，追跡をうまく継続できないという課題があった．複数人が歩行するような環境では，遮蔽が発生した場合でも追跡を継続できるようなシステムが求められる．


              \begin{figure}[H]
              \centering
              \begin{center}
              \centering
              \includegraphics[width=453pt]{occ_kal.png}
              \caption{遮蔽によって追跡がうまくいかない様子}
              \label{fig:occ_problem}
              \end{center} 
              \end{figure}


              処理速度も課題となっていた．計測人数に比例して処理速度が大きくなっていくため，複数の歩行者がいる場合，リアルタイムでの計測は難しかった．時系列画像作成，クラスタリング，カルマンフィルタの適用を並列で行うことで高速化を目指したものの，クラスタリングがボトルネックとなり高速化は実現できなかった．
              

       \section{ByteTrack}
       カメラ画像に対する複数物体追跡は，Multi Object Tracking（MOT）と総称され，様々な手法が提案されている．本研究では，その中でも極めて高い性能を発揮することで知られるByteTrack\cite{ByteTrack}のアルゴリズムを，2D-LiDAR画像に適用することを考えた．本節ではByteTrackの概要を紹介する．

              \subsection{Multi Object Tracking}
              Multi Object Tracking（MOT）とは複数物体を追跡する技術の総称である．MOT手法の多くは，検出(Detection)と追跡(Tracking)を切り離して考える，Tracking By Detectionという考え方を用いている．Trackingは，あるフレームで検出された物体と次のフレームで検出された物体同士をIDで紐づけることの繰り返しである．多くのMOT手法は，Trackingアルゴリズムの独自性に重点を置いている．

              Trackingで重要な課題となるのが，追跡対象が影に入った場合の対応である．一度影に入って検出できなくなった物体が，再び影から出てきたとき，影に入る以前と同じIDを付与しなければならない．近年主流になっているMOT手法の多くは，物体の視覚的特徴量を用いてこの課題に対応しようとしている．追跡対象の色や形といった見た目の特徴を保持しておく．それらの視覚的特徴量とカルマンフィルタなどによる予測を組み合わせることで，影に出入りした物体に正しいIDを付与できる確率が高まり，精度の高い追跡が実現できる．

              一方で，2D-LiDAR画像は周囲の物体との距離のみを示すため，カメラ画像と比べて視覚的な特徴量が極めて少ない．したがって，本研究において視覚的特徴量を使うアルゴリズムの導入は難しいと考えられた．そこで，本研究ではByteTrack\cite{ByteTrack}と呼ばれる手法を採用した．ByteTrackは，Trackingに視覚的特徴量を用いないにも関わらず，非常に高い性能を発揮できる手法として知られている．


              \subsection{BYTEアルゴリズム}
              ByteTrack\cite{ByteTrack}は，検出にYOLOX\cite{ge2021yolox}，追跡にBYTEアルゴリズムを用いたトラッカーの名称である．ここでは，ByteTrackの鍵となっているBYTEアルゴリズムについて紹介する．

              一般的なMOTの追跡アルゴリズムでは，閾値よりも信頼度の低い検出を切り捨てて追跡を行う．図\ref{fig:com}は，複数人が歩くカメラ映像に対して，一般的なアルゴリズムが検出と追跡を行っている様子である．Frame \(t_1\)において，真ん中を歩く人は信頼度0.8として検出され，追跡でも赤い枠で表されている．しかし，Frame \(t_2\)では左の人の影に入って信頼度が0.4に下がり，設定された閾値を下回ってしまったため，追跡は失われてしまっている．この切り捨ては，誤検出を追跡に採用しないようにするために行われる．すべての検出を追跡に採用すると，右端の誤検出も人として追跡されてしまう．

              \begin{figure}[H]
              \centering
              \begin{center}
                     \centering
                     \includegraphics[width=115mm]{com.png}
                     \caption[人物の検出と追跡(BYTEアルゴリズムの場合)]{人物の検出と追跡(一般的なアルゴリズムの場合)\newline (\cite{ByteTrack}図2より)}
                     \label{fig:com}
              \end{center} 
              \end{figure}


              一方で，BYTEアルゴリズムは信頼度の低い検出も追跡に用いる．まず，すべての検出を信頼度の高い検出\(D_{high}\)と低い検出\(D_{low}\)に分ける．それらを用いて，これまでのフレームを踏まえたカルマンフィルタの予測との紐づけを行う．1回目の紐づけでは，信頼度の高い検出\(D_{high}\)のみを使って紐づけを行う．信頼度の高い検出のうち過去の追跡と結びつかなかったものは，新たな追跡対象として追加される．ここまでは従来の方法と同様である．続いて，1回目の紐づけで結びつかなかった予測と信頼度の低い検出\(D_{low}\)の紐づけを行う．ここで結びつかなかった検出は切り捨てられる．以上のような流れで紐づけを行うことで，信頼度の低い検出\(D_{low}\)も無駄にすることなく追跡が行われる．また，信頼度の低い検出\(D_{low}\)は新たな追跡対象とはならないため，誤検出が追跡につながることも避けられる．

              \begin{figure}[H]
              \centering
              \begin{center}
                     \centering
                     \includegraphics[width=115mm]{bye.png}
                     \caption[人物の検出と追跡(BYTEアルゴリズムの場合)]{人物の検出と追跡(BYTEアルゴリズムの場合)\newline (\cite{ByteTrack}図2より)}
                     \label{fig:bye}
              \end{center} 
              \end{figure}


              \subsection{2D-LiDAR画像への適用}
              BYTEアルゴリズムを導入したByteTrackは，MOTにおけるState-of-the-Artな手法として注目を集めている．一方で，ByteTrackはカメラ画像に対する追跡技術であり，2D-LiDAR画像に対しても同様の追跡を実現できるかどうかは不明である．したがって本研究は，2D-LiDAR画像に対するByteTrackの適用可能性を，実計測データに対する追跡を行うことで検証する．




       \section{骨格推定}
       小林研究室では，2D-LiDARを用いた足元計測データから，歩行者の全身骨格を推定する研究が行われてきた\cite{suda2023}．本節では先行研究における3次元骨格推定の概要について説明する．


       \begin{figure}[H]
       \centering
       \begin{center}
              \centering
              \includegraphics[width=115mm]{sudasan.png}
              \caption[骨格推定の概要]{骨格推定の概要\newline (\cite{suda2023}図3.1より)}
              \label{fig:com}
       \end{center} 
       \end{figure}

              \subsection{学習データの作成}
              先行研究では，学習データのにおける骨格情報の取得のためにRGB-DカメラであるKinectを用いている．足元に設置した2D-LiDARで直進歩行を記録すると同時に，正面に設置したKinectで全身の骨格情報をあわせて取得して学習データとする．
              
              取得された2D-LiDARの点群データは，歩行者検出・追跡と同様に時系列画像として書き出す．この時系列画像から人物の領域を重心を中心に100×100ピクセルで切り出したものを，ネットワークへの入力とする．
              
              正解ラベルとなる骨格情報は，Kinectによって取得された25点の関節座標を用いる．個人差による身長や体格の影響を排除するため，腰の座標を原点とし，首と腰の距離を基準とした正規化を行った上で学習に用いる．

              \begin{figure}[H]
                     \centering
                     \includegraphics[width=115mm]{suda_learn.png}
                     \caption[Kinectを使った学習データの作成]{Kinectを使った学習データの作成(\cite{suda2023}図3.6より)}
                     \label{fig:suda_learn}
              \end{figure}

              \subsection{骨格推定モデル}
              骨格推定モデルには，画像認識等のタスクで高い性能を示すResNet-18を用いている．ImageNetで事前学習済みのResNet-18をベースとし，入力された時系列から25点の3次元骨格座標を出力する回帰モデルを構築している．
              損失関数には，平均二乗誤差（MSE）に加え，手足などの末端の動きを重視するための重み付けを行った独自の損失関数を用いている．

              先行研究における評価実験では，歩行データを用いた検証が行われ，提案モデルの有効性が確認されている．
              推定結果を可視化すると，歩行に伴う手足の振り上げや踏み出しといった動作が，正解データであるKinectの骨格情報に近い形で再現されていた．足元の2D-LiDAR情報のみから，上半身を含む全身の骨格姿勢を推定することが可能であることが示されている．


              %推定してる感じがわかる図
              %あとここもっと詳しく説明したいね





\chapter{システムの概要}
本研究では，2D-LiDARで計測した複数歩行者の検出・追跡と骨格推定をリアルタイムで行うことができる，統合的なシステムを実現した．本章ではシステムの概要を示す．



本システムは，計測データの取得と結果の描画を行うPCと，深層学習モデルの推論などの重い計算処理を行うGPUを搭載したPC(以下計算用マシン)の2台の連携によって動作する．

全体の処理の流れは以下の通りである．
\begin{enumerate}
       \item 手元のPCが2D-LiDARから距離データを取得
       \item 取得した距離データを計算用マシンへ送信
       \item 計算用マシンにて受信した距離データを直交座標系へ変換・MHIを作成
       \item ByteTrackによる追跡処理と骨格推定モデルによる推定処理を並列に実行
       \item 計算用マシンのメインスレッドが各処理結果を手元のPCへ逐次送信
       \item 受信した結果を用いて3次元描画
\end{enumerate}

この構成により，計算負荷の高い処理を計算用マシンに集約し，リアルタイムでの計測と描画を実現している．本章では，各処理の詳細について述べる．


       \section{2D-LiDARによる計測}
       
              \subsection{2D-LiDARの仕様}
              LiDAR (light detection and ranging)とは，光でスキャニングしながら検出物までの距離を測定する二次元走査型の光距離センサである.本研究では北陽電機の UTM-30LX\cite{lidar}(図\ref{fig:lid},表\ref{tab:lid})を使用する．2D-LiDARと同じ高さの水平方向周囲270度に存在する物体との距離を正確に計測することができる．仕様を表\ref{tab:lid}に示す．

              \begin{figure}[H]
              \centering
              \begin{center}
              \centering
              \includegraphics[width=60mm]{lidar.jpg}
              \caption{UTM-30LX}
              \label{fig:lid}
              
              \end{center} 
              \end{figure}


              \begin{table}[H]
              \centering
              \caption{{UTM-30LX} の仕様}
              
              \begin{tabular}{|c|l|} \hline
              光源 & 半導体レーザλ=905nm，FDAレーザ安全クラス 1\\ \hline
              電源電圧 & DC12V±10\% \\ \hline 
              電源電流 & パワーON時Max1A，定常時0.7A以下\\ \hline
              検出距離 & 検出保証値 0.1〜30m,最大検出距離 60m(出力限界値)\\ \hline
              検出体 & 最小検出物 130mm(10m):距離により変動する \\ \hline
              測距制度 & 0.1〜10m:±30mm， 10〜30m:±50mm \\ \hline
              走査角度 & 270度\\ \hline
              角度分解能 & 約0.25度(360°/1440分割)\\ \hline
              走査時間 & 25ms(モータ回転数 2400rpm)\\ \hline
              インターフェース & USB Ver2.0 FSモード(12Mbps)\\ \hline
              出力 & OUTPUT 1点 同期出力 \\ \hline
              重量 & 210g(ケーブルを除く)\\ \hline

              \end{tabular}
              \label{tab:lid}
              \end{table}


              \newpage
              2D-LiDARは，足首を計測できる高さとして床から約20cmの位置に設置する(図\ref{fig:lidar_set})．


              \begin{figure}[H]
                     \centering
                     \includegraphics[width=115mm]{lidar_set.jpeg}
                     \caption[2D-LiDARの設置]{2D-LiDARの設置}
                     \label{fig:lidar_set}
              \end{figure}


              \subsection{距離データの取得}
              2D-LiDARより取得されるのは，計測平面における周囲の物体との距離データである．周囲270度を0.25度ずつ走査するため，1080点の距離データが取得される．本システムでは，取得した距離データをそのまま計算用の計算用マシンへ送信している．手元のマシンで座標変換して画像化する場合，2次元画像の送受信が必要となり処理速度が低下するため，距離データをそのままテキストデータとして送信することでシステムの高速化を図った．




       \section{計算用マシンにおける処理構成}

       本節では，計算用マシンにおける全体的な処理の流れについて述べる．

       計算用マシンでは，受信した距離データをもとに時系列画像を作成し，検出・追跡と骨格推定を行う．それぞれの処理にかかる時間が異なることから，本システムではマルチスレッドにて各処理を並列して行う．メインスレッドに並列して，検出・追跡用スレッドと骨格推定用スレッドが動作する(図\ref{fig:multi})．

       メインスレッドでは，距離データの受信と時系列画像の作成，各処理より得られた結果の送信を行う．各スレッドでの処理の結果はグローバル変数へ格納され，メインスレッドはそれらの更新にかかわらず一定のタイミングで手元のPCへの送信を行う．これによって，各処理の時間に影響を受けることなくシステム全体が動作する．
       
       \begin{figure}[H]
              \centering
              \includegraphics[width=115mm]{multi.png}
              \caption[並列処理の処理構成]{並列処理の処理構成}
              \label{fig:multi}
       \end{figure}
       

       
       \section{距離データの画像処理}
       本節では，メインスレッドにおける画像処理について述べる

             \subsection{2次元画像の作成}
              メインスレッドでは，受信した距離データを2次元画像に変換する．取得した距離データのラジアン角度を求め，直交座標系に変形してプロットする(図\ref{fig:sensing})．このように描画された2次元画像を本稿では距離画像と呼ぶ．また，現在の1フレームの距離画像を，本稿では現在画像と呼ぶ．

              \begin{figure}[H]
                     \centering
                     \includegraphics[width=115mm]{image_Sensing_neo.png}
                     \caption[2D-LiDARによる計測と変換]{2D-LiDARによる計測と変換}
                     \label{fig:sensing}
              \end{figure}

              


              \subsection{時系列画像の作成}
              先行研究と同様に，複数フレームの距離画像を重ね合わせた画像を時系列画像と呼ぶ．時系列画像は，人間などの対象物の動きを1枚の画像で表現する，Motion History Image (MHI) \cite{bobick2001recognition}という手法を用いて作成する．MHIでは，現在のフレームに近いほど明るく，過去のフレームほど暗く描画することで，対象の動きを表す．
              本研究においては，フレームが更新される度に前フレームでの時系列画像の輝度を一定量減らし，最新のフレームを重ね合わせることで時系列画像を作成する(図\ref{fig:create_mhi})．
              
              \begin{figure}[H]
                     \centering
                     \includegraphics[width=115mm]{create_MHI.png}
                     \caption[時系列画像の作成]{時系列画像の作成}
                     \label{fig:create_mhi}
              \end{figure}

  


       \section{人物の検出と追跡}

       本節では，検出・追跡用スレッドにて行われる処理について述べる．

       本研究では，カメラ画像に対する複数物体追跡手法を2D-LiDARによる計測に導入することで，従来の手法の課題解消を目指した．2D-LiDAR画像は情報量が極めて少ないため，追跡対象の見た目の特徴を追跡の手がかりとしないにも関わらず高い性能を発揮しているByteTrackを採用している．ByteTrackによる複数物体追跡は，YOLOXによる検出とBYTEアルゴリズムによる追跡によって実現される．それらの処理は計算用マシンの検出・追跡用スレッドで実行される．

              \subsection{YOLOXによる検出}
              本研究においても，従来のByteTrackと同様にYOLOXを用いた人物の検出を目指す．しかし，従来のYOLOXはカメラ画像中の人物や物体を検出できるような学習がなされているため，本システムでは新たな転移学習が必要となった．

              実際に歩行者の足元の様子を2D-LiDARで計測し，時系列画像を作成してアノテーションを行うことで学習データとした．学習には，YOLOXシリーズの中で最もパラメータ数が多く高精度なYOLOX-Xモデルを採用している．エポック数は100に設定した．最終的に，2499枚の学習データ，650枚のテストデータを用いて学習を行い，十分な検出精度が得られることを確認した．

     

              \subsection{BYTEアルゴリズムによる追跡}
              YOLOXによって検出された人物の位置情報と信頼度を入力として，BYTEアルゴリズムを用いた追跡を行う．
              BYTEアルゴリズムは，追跡の紐づけに対象の視覚的特徴量を用いないため，2D-LiDARの時系列画像においても大きなシステムの改変を行うこと無く導入できる．
       
              追跡におけるハイパーパラメータは，本稿における実験では以下のように設定している．
              

              \begin{table}[H]
                     \centering
                     \caption{ByteTrackのパラメータ設定}
                     \begin{tabular}{|l||c|} \hline
                            Parameters & Value \\ \hhline{|=||=|}
                            track\_thresh & 0.6 \\ \hline
                            match\_thresh & 0.9 \\ \hline
                            aspect\_ratio\_thresh & 1.1 \\ \hline
                            track\_buffer & 150 \\ \hline
                            conf & 0.01 \\ \hline
                            min-box-area & 100 \\ \hline
                     \end{tabular}
                     \label{tab:bytetrack_param}
              \end{table}



              \subsection{追跡結果の送信}
              YOLOXによる検出，BYTEアルゴリズムによる追跡を経て得られた追跡結果は，追跡対象ごとにIDと座標情報がセットとなり出力される．これらはグローバル変数に格納され，メインスレッドによって手元のPCへ送り返される．


       \newpage

       \section{骨格推定}


       本節では，骨格推定用スレッドで行われる処理について述べる．

       
       骨格推定を行うために，まずは計測域全体の時系列画像から歩行者の部分のみを切り出す必要がある．検出・追跡によって得られたバウンディングボックスの位置情報を元に，骨格推定モデルに合わせて100×100ピクセルの画像を切り出す．歩行者の動きによってはボックスの位置がズレてはみ出すことがあるため，一度大きな領域の画像へ広げ，重心計算を行うことで正確に足元を切り出す．図\ref{fig:g_crop}において，黄色が追跡によって得られたバウンディングボックスである．これを白色の領域に広げて重心を計算し，青色の領域を再度切り出している．

       \begin{figure}[H]
              \centering
              \includegraphics[width=115mm]{g_crop.png}
              \caption[重心計算を用いた画像の切り出し]{重心計算を用いた画像の切り出し}
              \label{fig:g_crop}
       \end{figure}


       %重心再計算して切り出す図

       得られた時系列画像に対して，先行研究で得られたモデルを用いて骨格推定を行う\cite{suda2023}．
       このモデルは，ImageNetで事前学習済みのResNet-18をベースとした回帰モデルであり，入力されたMHIから25点の3次元骨格座標を直接推定する．
       学習時には，平均二乗誤差(MSE)に基づく損失関数に加え，手足の末端など誤差が大きくなりやすい部位に対して動的に重み付けを行う独自の損失関数を用いることで，歩行動作における手足の振りをより正確に再現できるよう学習されている．
       推定結果は25点の3次元座標として出力される．それらの結果は検出・追跡と同様にグローバル変数に格納され，メインスレッドによって手元のPCへ送り返される．

       \begin{figure}[H]
              \centering
              \includegraphics[width=115mm]{estimate.png}
              \caption[骨格推定の様子]{骨格推定の様子}
              \label{fig:estimate}
       \end{figure}


       \newpage

       \section{結果の表示}

       本節では，計算用マシンより送り返された各結果の処理方法について述べる．本システムでは，2次元平面での検出・追跡に関する結果表示と，3次元空間での骨格推定を含めた結果表示を実装した．


              \subsection{2次元平面での結果表示}

              2D-LiDARによって計測された点群を2次元平面に描画し，その上に検出・追跡結果を描画することで追跡の様子が可視化される(図\ref{fig:2d})．

              \begin{figure}[H]
                     \centering
                     \includegraphics[width=115mm]{2d.png}
                     \caption[2次元平面での結果表示]{2次元平面での結果表示}
                     \label{fig:2d}
              \end{figure}

              \subsection{統合的な表示の実装}
              検出・追跡の結果と推定された骨格を統合し，3次元空間での可視化を行う．実際の歩行の様子に近い状態での出力となり，直感的な計測結果の確認が可能になる．描画ライブラリにはOpenGLを用いている．
       
              まず，2D-LiDARから得られる点群データを，3次元空間内において平面として描画する．次に，推定された骨格を描画していく．この際，追跡結果の座標情報に基づいて，骨格情報を描画する座標を決定する．足首を示す骨格点と2D-LiDAR点群のZ座標を揃えることで，実際に点群上を骨格が歩いているような表示を実現した(図\ref{fig:3d})．


              %システム全体を表現する図

              \begin{figure}[H]
              \centering
              \begin{center}
                     \centering
                     \includegraphics[width=115mm]{3d.png}
                     \caption[３次元描写の様子]{３次元描写の様子}
                     \label{fig:3d}
              \end{center} 
              \end{figure}

              \subsection{崩れた骨格の補完}
              現在の骨格推定の精度はまだ改善の余地があり，明確に崩れた骨格が推定される場合もある(図\ref{fig:ske_bad})．
              正しい骨格を推定できたフレームと明確に崩れてしまったフレームが連続する場合，描画される骨格形状が急激に変化するため，歩行している様子がわかりにくくなってしまう．
              
              そこで本システムでは，時間的な連続性を利用した補完処理を導入した．明らかに崩れた骨格が推定された場合には，そのフレームの推定結果を破棄する．代わりに，直前のフレームにおける推定結果をそのまま保持して描画に使用する．この処理により，崩れた骨格による表示の乱れを抑え，スムーズで違和感の少ない結果出力を実現した．

              \begin{figure}[H]
              \centering
              \begin{minipage}{0.4\columnwidth}
                     \centering
                     \includegraphics[width=\columnwidth]{ske_good.png}
                     \caption[正しい骨格]{正しい骨格}
                     \label{fig:ske_good}
              \end{minipage}
              \hspace{0.04\columnwidth} %
              \begin{minipage}{0.4\columnwidth}
                     \centering
                     \includegraphics[width=\columnwidth]{ske_bad.png}
                     \caption[崩れた骨格]{崩れた骨格}
                     \label{fig:ske_bad}
              \end{minipage}
              \end{figure}



       





\chapter{実験と考察}
 本研究で提案するシステムの有効性を検証するために実験を行った．本章における実験は，大きく2つのフェーズに分かれる．
 
 まず4.1節では，歩行者の検出・追跡に関する性能改善について評価する．ここでは，MOT (Multi Object Tracking) 分野で一般的に用いられる評価指標を用いて，ByteTrackベースの提案手法と従来の手法の性能を比較し，その結果について考察する．
 
 続く4.2節では，骨格推定を含めた統合システムの評価を行う．実際に複数人が歩行する環境においてシステムを稼働させ，検出・追跡の結果に基づいて骨格推定が行われているか確認し，各状況における成功・失敗の要因について考察を行う．

       \section{検出・追跡性能の比較}
       本節では，歩行者の検出・追跡に関する性能改善について評価する．複数人の歩行に対して，今回提案するByteTrackベースの手法と従来の手法のそれぞれで追跡を行う．
              \subsection{実験の環境}
                     歩行を行うエリアは屋内の3m×3.5mのエリアである．近接したすれ違いや，一方の足が他方の足に隠れるシーンが発生するような歩行を行う．歩行人数は2人と4人である．

                     \begin{figure}[H]
                            \centering
                            \includegraphics[width=115mm]{exp_4.png}
                            \caption[歩行の様子]{歩行の様子}
                            \label{fig:exp_4}
                     \end{figure}

                     計測は1台の2D-LiDARによって行われる．ByteTrackベースの提案手法で，リアルタイムに追跡を行う，また，従来の手法でも同じ歩行に対して追跡を行う．2D-LiDARから受け取る距離データをテキストファイルとして書き出し，従来の追跡プログラムで読み込むことで，従来の手法でも追跡を行った．

                     %歩行の様子の図

              \subsection{評価指標}
                     Multi Object Trackingにおいては，さまざまな指標によって追跡の精度が定量的に評価される．本研究においては，その中でも特に一般的である，MOTA\cite{bernardin2008evaluating}，IDF1\cite{ristani2016performance}の2つの指標を評価に用いる．

                     各指標の計算には，Pythonのpy-motmetricsライブラリ\cite{py-mot}を利用した．2D-LiDARより得られた画像に対して，手動でアノテーションを行い正解データを作成する．各追跡手法よりアノテーションデータを取得し，正解データと照らし合わせることで評価指標が計算できる．

                     \subsubsection{MOTA}

                     MOTA\cite{bernardin2008evaluating}は，MOTの評価指標として広く用いられている．定義を式5.1に示す．分母は各フレームにおける正解の数の総和である．追跡対象人数とフレーム数の積によって得られる．分子は，追跡における3つのミスの和である．FP (False Positive)は偽陽性を意味し，人物検出においては人物ではない部分が誤って検出されてしまうミスを指す．FN (False Negative)は偽陰性を意味し，人物追跡においては人物であるにも関わらず検出されないミスを指す．IDswはIDSwitchの略であり，人物に付与されていたIDが変化してしまうことを指す．分母の\(g_t\)は，各フレームにおける正解データの数を表す．以上より，分数部分は正解の数に対するミスの割合を示すことになる．これを1から引くことによってMOTAが求められる．数値が1に近いほど精度が高いことを意味する．


                     \begin{equation}
                     MOTA = 1 - \frac{\sum_t(FP_t + FN_t + IDsw_t)}{\sum_tg_t}
                     \end{equation}

                     \subsubsection{IDF1}

                     MOTAには，追跡の持続性を評価することができないという弱点があった．IDF1\cite{ristani2016performance}は，IDFP (ID False Positive)やIDFN (ID False Negative)といったIDを基準とした数値を用いることで，MOTAの弱点を解消した評価基準である．定義を式5.2に示す．IDFPは，従来のFPに加えて，IDの付与を誤っている場合もミスとしてカウントする．同様にIDFNは，従来のFNに加えて，IDの付与を誤っている場合もミスとしてカウントする．IDTPはすべての検出や正解からIDFPもしくはIDFNを引くことで求められ，正しく検出されなおかつIDの付与も合っている検出の数を示す．これらを用いて計算されるIDF1は，正しいIDを多くのフレームで付与できているほど高い数値となる．

                     \begin{equation}
                     IDF1 = \frac{2IDTP}{2IDTP + IDFP + IDFN}
                     \end{equation}


         
              \subsection{結果と考察}
              
              2人による歩行，4人による歩行のそれぞれに対して上記の評価指標を計算した．結果を表に示す(表\ref{tab:score2}，表\ref{tab:score4})．FP (False Positive)は，人物ではない部分が誤って検出されてしまったフレーム数を示し，FN (False Negative)は，人物が検出されなかったフレーム数を示す．IDsw (ID Switch)は，人物に付与されていたIDが変化してしまった回数を示す．
              
              \begin{table}[H]
                     \centering
                     \caption{性能評価(歩行人数：2人)}
                     
                     \begin{tabular}{|l||r|r|r||r|r|} \hline
                            & FP & FN & IDsw & MOTA & IDF1\\ \hhline{|=|=|=|=|=|=|}
                            クラスタリング＋カルマンフィルタ & 54 & 90 & 6 & 0.9175 & 0.625\\ \hline
                            ByteTrack & 20 & 290 & 0 & 0.8295 & 0.9127\\ \hline
                            
                     
                     \end{tabular}
                     \label{tab:score2}
              \end{table}


              \begin{table}[H]
                     \centering
                     \caption{性能評価(歩行人数：4人)}
                     
                     \begin{tabular}{|l||r|r|r||r|r|} \hline
                            & FP & FN & IDsw & MOTA & IDF1\\ \hhline{|=|=|=|=|=|=|}
                            クラスタリング＋カルマンフィルタ & 124 & 313 & 25 & 0.8401 & 0.5342\\ \hline
                            ByteTrack & 4 & 466 & 0 & 0.8374 & 0.9117\\ \hline
                            
                     
                     \end{tabular}
                     \label{tab:score4}
              \end{table}


              どちらの歩行においても，MOTAは同程度，もしくはクラスタリングとカルマンフィルタを用いる従来の手法のほうが高い数値なった．クラスタリングによる人物検出は，点群の密集を人物であると認識しているため，遮蔽などで足の形が通常と異なる場合にも検出性能が落ちにくい(図\ref{fig:kal_keep})．一方で，ByteTrackを用いた提案手法は，YOLOXによって学習された足の形を検出しているため，遮蔽などで理想的な足の形がとれない場合などに検出に失敗する場合がある(図\ref{fig:byte_lost})．このためFalse Negativeが増加し，従来の手法と比べてMOTAが伸びなかったと考えられる．

              \begin{figure}[H]
                     \centering
                     \begin{minipage}{0.48\columnwidth}
                            \centering
                            \includegraphics[width=\columnwidth]{kal_keep.png}
                            \caption{従来手法による追跡}
                            \label{fig:kal_keep}
                     \end{minipage}
                     \hspace{0.02\columnwidth} %
                     \begin{minipage}{0.48\columnwidth}
                            \centering
                            \includegraphics[width=\columnwidth]{byte_lost.png}
                            \caption{提案手法による追跡}
                            \label{fig:byte_lost}
                     \end{minipage}
                     \caption{提案手法が検出に失敗する場面}
                     \label{fig:detect_fail}
              \end{figure}

              一方で，IDF1はByteTrackを用いた提案手法のほうが大幅に高くなった．これは，人物同士が接近したり遮蔽が発生した際に，これまでと違うIDを付与してしまうIDスイッチが全く発生しなかったためであると考えられる．4人での歩行であっても，最初から最後まで全員に正しいIDを付与し続けることができた．複数人が接近する際に正しい検出が失われた場合でも，検出が正常に戻れば正しいIDを再び与えることができる(図\ref{fig:byte_near})．一方で，カルマンフィルタを用いて追跡を行う従来の手法では，検出が途切れるとほとんどの場面でIDが切り替わってしまっている(図\ref{fig:kal_near})．

              \begin{figure}[H]
                     \centering
                     \begin{minipage}{\columnwidth}
                            \centering
                            \includegraphics[width=\columnwidth]{kal_near.png}
                            \caption{従来手法(IDスイッチが発生)}
                            \label{fig:kal_near}
                     \end{minipage}
                     \\ \vspace{10pt}
                     \begin{minipage}{\columnwidth}
                            \centering
                            \includegraphics[width=\columnwidth]{byte_near.png}
                            \caption{提案手法(IDを維持)}
                            \label{fig:byte_near}
                     \end{minipage}
                     \caption{近接時のID維持性能の比較}
                     \label{fig:near_compare}
              \end{figure}

              
              本実験の結果より，提案手法は従来手法と比較してMOTAの劇的な向上は見られなかったものの，追跡の持続性を示すIDF1において大幅な性能向上が確認された．歩行者の行動を理解するためのシステムにおいて，対象を途切れることなく追跡し，個々の同一性を保証することは非常に重要である．本手法が達成した高いIDF1は，複雑な環境下でも人物のIDを一貫して保持できていることを示している．特に，複数人が接近する・互いに遮蔽を作る環境においてもIDスイッチを起こさずに追跡を継続できた点は，提案手法の大きな利点である．
              
              さらに，本システムではこれらの検出・追跡を，計算用マシンとの連携による並列処理によってリアルタイムに実現している．高精度な追跡とリアルタイム動作の両立は，実環境で使用しやすい人物計測システムの実装に向けて重要な進歩である．

       \section{統合したシステムの評価}
       本節では，骨格推定を含めた統合システムの評価を行う.
       
              \subsection{シンプルな歩行における骨格推定}
              まず，骨格推定モデルを学習する際に学習データとして用いた，シンプルな直進歩行に対して統合システムを実行して骨格を推定する．行う歩行は，2D-LiDARに向かって直進，2D-LiDARから離れる方向に直進，2D-LiDARの前を横断の3種類である．

          
                     \subsubsection{2D-LiDARに向かって直進する場合}
                  

                     2D-LiDARに向かって直進する歩行を計測すると，非常に正確な骨格が推定できた(図\ref{fig:front})．実際の歩行の様子と同じように，足の動きや腕の振りが再現されている．

                     \begin{figure}[H]
                            \centering
                            \includegraphics[width=115mm]{front.png}
                            \caption[正しい推定]{正しい推定}
                            \label{fig:front}
                     \end{figure}

                     
                     \subsubsection{2D-LiDARから離れる方向に直進する場合}

                     2D-LiDARから離れていく方向に直進する歩行を計測すると，多くの場合においては正確な骨格が推定できた．一方で，明確に崩れた骨格が推定されるフレームもいくつか存在した(図\ref{fig:back_miss})．学習データにおける2D-LiDARから離れる歩行は，多くが画像をはみ出る形で足が描画されていた．本システムでは重心の再計算により，画像をはみ出すことは極めて少なくなっている．そのために，2D-LiDARから離れる歩行では崩れた骨格が見られたのではないかと考える．

                     \begin{figure}[H]
                            \centering
                            \includegraphics[width=115mm]{back_miss.png}
                            \caption[明確に崩れてしまった推定]{明確に崩れてしまった推定}
                            \label{fig:back_miss}
                     \end{figure}

                     \subsubsection{2D-LiDARの前を横断する場合}

                     2D-LiDARの前を横断する場合は，左右どちらの向きであってもおおよそ正しい推定ができた(図\ref{fig:right})．明確に崩れた骨格が推定されるフレームも少なかった．一方で，足の振りや腕の振りが実際よりも大きく推定されるフレームが多かった．これは，切り抜いた時系列画像中で足の動きがはみ出してしまっていたことに起因すると考えられる．

                     \begin{figure}[H]
                            \centering
                            \includegraphics[width=115mm]{right.png}
                            \caption[実際よりも動きが大きくなってしまった推定]{実際よりも動きが大きくなってしまった推定}
                            \label{fig:right}
                     \end{figure}
                     

              \subsection{実環境に近い歩行における骨格推定}
              つづいて，実際に計測を行う環境に近い複数人の歩行に対して，統合システムを実行して骨格を推定する．
              

              最も正しく骨格を推定できたのは，2D-LiDARの前を横切るような歩行であった(図\ref{fig:unit_across})．これは，前節で述べた2D-LiDARの前を横断する場合と全く同じ状況であり，学習データに極めて近い計測ができていたためであると考えられる．

              \begin{figure}[H]
                     \centering
                     \includegraphics[width=115mm]{unit_across.png}
                     \caption[2D-LiDARの前を横切る歩行での統合結果]{2D-LiDARの前を横切る歩行での統合結果}
                     \label{fig:unit_across}
              \end{figure}
              %横切る様子にフィーチャーした図


              一方で，2D-LiDARに向かって直進する歩行や離れるように直進する歩行では推定精度が低下した．
              歩行の向きとしては，前節の2D-LiDARに向かって直進する場合に近い．しかし，2D-LiDARから見て正面ではなく斜め前での歩行であったため，時系列画像に残る足の形が正面から見た形と変化してしまい，推定精度に影響したと考えられる．

              %正面と斜めのMHI並べる

              また，直進ではなく曲線的な動きをメインとする歩行においては，ほとんどの場合で崩れた骨格となってしまった．また，推定できたフレームであっても，歩行方向と異なる向きでの推定が多かった(図\ref{fig:harikae})．現在の学習データには斜めの歩行や曲線的な歩行が含まれていないためであると考えられる．

              \begin{figure}[H]
                     \centering
                     \includegraphics[width=115mm]{harikae.png}
                     \caption[歩行方向と異なる向きでの推定]{歩行方向と異なる向きでの推定}
                     \label{fig:harikae}
              \end{figure}

              %張替の図

              実際の計測では，歩行者は直進歩行のみをする場合は考えにくく，様々な方向に直線・曲線問わず歩行することを想定する必要がある．それらの歩行から正しく骨格を推定するためには，骨格推定モデルのさらなる性能向上が求められる．学習データの幅を広げ，より多様な歩行から骨格を推定できるようにする必要がある．

       \section{統合システムに関する考察}
              2つの実験を通じて，検出・追跡から骨格推定，そして3次元空間への描画までの一連の処理が，大きな遅延なくリアルタイムで動作することを確認した．
              骨格推定については，歩行方向によって精度が低下するなどの課題が残るものの，2D-LiDARによって計測されたわずかな情報から，プライバシーを侵害することなく空間内の人物の振る舞いを3次元的に再現できたことは大きな成果である．
              本システムは，カメラを設置しにくい公共施設など，従来の手法では計測が難しかった場面においても，詳細な人物行動計測を可能にする手段として広く活用できると考えられる．


            




\chapter{おわりに}
       \section{まとめ}
       本稿では，足元の高さに設置した2D-LiDARを用いた人物行動理解に関する取り組みについて述べた．

       これまでの検出・追跡システムにおける各課題を解消し，高速かつ高性能なシステムを実装した．カメラ画像に対する追跡手法であるByteTrackのアルゴリズムを導入し，持続性の高い追跡をリアルタイムで実行できるようになった．実際に複数人の歩行を追跡し，その性能を確認した．追跡の持続性という観点で，従来よりも良い結果を得ることができた．

       また，骨格推定システムとの融合を行い，プライバシーに配慮した総合的な人物行動の計測システムを構築した．計測・追跡で作成した時系列画像から人物の切り出しを行い，従来の骨格推定モデルを適用することで3次元骨格の推定を行う．これらの一連の流れをリアルタイムで行えるシステムを構築した．実際に複数人の歩行に対してシステムを適用し，計測から推定までリアルタイムで実行できることを確認した．一方で，実環境に近い歩行での骨格推定にはいくつかの課題があることもわかった．
   
       \newpage
       \section{今後の課題}
       本研究の成果と，明らかになった課題を踏まえ，今後の展望について述べる．
       
       \subsection{多様な歩行動作への対応}
       第4章の実験結果において，直進以外の歩行や複雑な軌道を描く歩行に対して，骨格推定の精度が低下する傾向が見られた．これは，現在の骨格推定モデルの学習データが，単純な直進歩行のみで構成されていることよると考えられる．
       実環境における歩行者の動きは多岐にわたるため，斜め方向への移動や旋回，不規則な歩行など，より多様な動作パターンを学習データに追加する必要がある．これにより，あらゆる歩行動作に対応する骨格推定が可能になると考えられる．
       
       \subsection{実環境における大規模な評価}
       本研究における実験は，3m×3.5mという限定された空間内で行った．しかし，実際の応用場面は，より広範囲かつ多数の歩行者が往来する環境であることが想定される．
       今後は，今回より広い計測範囲や，5人以上の多人数が混在する環境において評価実験を行う必要がある．また，骨格推定における定量的な評価の導入も検討する必要がある．

       
       


\chapter*{外部発表}
\addcontentsline{toc}{chapter}{外部発表}

\begin{itemize}
	\item 廣中優平，鈴木亮太，小林貴訓，“2D-LiDARによる足元計測に基づくByteTrackを用いた歩行者追跡”，第30回画像センシングシンポジウム，2024．
\end{itemize}

\newpage

% 参考文献：bibtexを使う場合
%
\bibliographystyle{junsrt} % bstファイル名
\bibliography{books} % bibファイル名
\label{sannkoubunnkenn_chapter}

% 参考文献：直接記述する場合
% \begin{thebibliography}{99}
% \label{sannkoubunnkenn_chapter}
% 
% %% 程研究室参考文献形式
% 
% % 学術雑誌論文
% \bibitem{tagawa98}
% 多川 孝央, 大堀 順也, 程 京徳, 牛島 和夫: 相関論理における強相関性原理,
%         人工知能学会誌, Vol. 13, No. 3, pp. 387-394, 1998年5月.
% 
% \bibitem{Nonaka99}
% Yusuke NONAKA, Jingde CHENG, and Kazuo USHIJIMA: A Tasking Deadlock
%         Detector for Ada 95 Programs, Ada User Journal, Vol. 20, No. 1,
%         pp. 79-92, April 1999.
% 
% % 単行本
% \bibitem{ChengXX}
% 程 京徳: 相関論理入門, 何らか出版社, 200?年?月.
% 
% \bibitem{Jin01}
% Qun JIN, Jie LI, Nan ZHANG, Jingde CHENG, Clement YU, and Shoichi
%         NOGUCHI: Enabling Society with Information Technology,
%         Springer-Verlag, November 2001.
% 
% \bibitem{Hennessy93}
% Matthew Hennessy著, 荒木 啓二郎, 程 京徳 共訳：
% プログラミング言語の意味論入門, サイエンス社, 1993年12月.
% 
% % 単行本などに編集された章，論文
% \bibitem{Cheng91}
% Jingde CHENG: Relevance Logic and Entailment Logic, in I. Nakada and
%         M. Hagiya (Eds.), ``Software Science and Engineering,''
%         pp. 189-211, World Scientific, November 1991.
% 
% \bibitem{Nonaka00}
% Yusuke NONAKA, Jingde CHENG, and Kazuo USHIJIMA: A Supporting Tool for
%         Development of Self-measurement Ada Programs, in H. B. Keller
%         and E. Ploedereder (Eds.), ``Reliable Software Technologies -
%         Ada-Europe 2000, 5th International Conference on Reliable
%         Software Technologies, Potsdam, Germany, June 2000,
%         Proceedings,'' Lecture Notes in Computer Science, Vol. 1845,
%         pp. 69-81, Springer-Verlag, June 2000.
% 
% % 国際会議，国内シンポジウム論文集論文
% \bibitem{Goto01}
% Yuichi GOTO, Daisuke TAKAHASHI, and Jingde CHENG: Parallel Forward
%         Deduction Algorithms of General-Purpose Entailment Calculus on
%         Shared-Memory Parallel Computers, Proceedings of the ACIS 2nd
%         International Conference on Software Engineering, Artificial
%         Intelligence, Networking \& Parallel/Distributed Computing,
%         pp. 168-175, Nagoya, Japan, August 2001.
% 
% \bibitem{Koide01}
% 小出 雅人, 程 京徳: インターネット上でカードゲームを行うための汎用プロト
%         コル群の開発, 情報処理学会第６回ゲーム・プログラミング国際ワーク
%         ショップ論文集, pp. 78-85, 箱根, 日本, 2001 年10月.
% 
% % 博士，修士，卒業論文
% \bibitem{Goto05}
% 後藤 祐一: 強相関論理に基づいた自動前向き演繹とその応用, 埼玉大学大学院
% 	理工学研究科情報数理科学専攻博士論文,2005年3月.
% 
% \bibitem{Goto02}
% 後藤 祐一: 強相関論理と汎用前向き自動帰結演算システム EnCal を用いた知識
% 	発見, 埼玉大学大学院理工学研究科情報システム工学専攻修士論文,2003年
% 	2月.
% 
% \bibitem{Goto00}
% 後藤 祐一: 汎用前向き自動帰結演算システムEnCalの共有メモリ型並列計算機上
% 	での並列化, 埼玉大学工学部情報システム工学科卒業論文, 2001年2月.
% 
% 
% % 企業や製品のWebページなど
% % \newblockは後ろに続く文字列を一つの塊としてみなす命令
% \bibitem{cem}
% {Common Criteria Project}:
% \newblock CEM v3.1,
% \newblock \\http://www.commoncriteriaportal.org/thecc.html
% 
% \bibitem{ccportal}
% {Common Criteria Project}:
% \newblock Common Criteria Portal,
% \newblock \\http://www.commoncriteriaportal.org/
% 
% \end{thebibliography}

% 付録
%\appendix % 以下，付録
%\chapter{▽△▽△}
%\section{ほげほげ}
%\section{ほりゃほりゃ}
%\chapter{▽△▽△}
%\section{ほげほげ}
%\section{ほりゃほりゃ}

% 索引． mendexかmkindexで作成
\printindex

%目次にIndexを表示させる場合はmendexかmkindex実行後に作成される
% hogehoge.idmファイルのtheindex環境の中で下記命令を置く
%\addcontentsline{toc}{chapter}{Index}

\end{document}

